{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7abb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5d6acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching headlines for 2018/01/01\n",
      "Failed to fetch headlines for 2018/01/01: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/01\n",
      "Fetching headlines for 2018/01/02\n",
      "Failed to fetch headlines for 2018/01/02: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/02\n",
      "Fetching headlines for 2018/01/03\n",
      "Failed to fetch headlines for 2018/01/03: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/03\n",
      "Fetching headlines for 2018/01/04\n",
      "Failed to fetch headlines for 2018/01/04: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/04\n",
      "Fetching headlines for 2018/01/05\n",
      "Failed to fetch headlines for 2018/01/05: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/05\n",
      "Fetching headlines for 2018/01/06\n",
      "Failed to fetch headlines for 2018/01/06: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/06\n",
      "Fetching headlines for 2018/01/07\n",
      "Failed to fetch headlines for 2018/01/07: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/07\n",
      "Fetching headlines for 2018/01/08\n",
      "Failed to fetch headlines for 2018/01/08: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/08\n",
      "Fetching headlines for 2018/01/09\n",
      "Failed to fetch headlines for 2018/01/09: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/09\n",
      "Fetching headlines for 2018/01/10\n",
      "Failed to fetch headlines for 2018/01/10: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/10\n",
      "Fetching headlines for 2018/01/11\n",
      "Failed to fetch headlines for 2018/01/11: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/11\n",
      "Fetching headlines for 2018/01/12\n",
      "Failed to fetch headlines for 2018/01/12: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/12\n",
      "Fetching headlines for 2018/01/13\n",
      "Failed to fetch headlines for 2018/01/13: 403 Client Error: Forbidden for url: https://www.wsj.com/news/archive/2018/01/13\n",
      "Fetching headlines for 2018/01/14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching headlines for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     headlines \u001b[38;5;241m=\u001b[39m fetch_headlines_for_date(date_str)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m headline \u001b[38;5;129;01min\u001b[39;00m headlines:\n\u001b[0;32m     41\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: date_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheadline\u001b[39m\u001b[38;5;124m'\u001b[39m: headline})\n",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m, in \u001b[0;36mfetch_headlines_for_date\u001b[1;34m(date)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_headlines_for_date\u001b[39m(date):\n\u001b[0;32m      2\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.wsj.com/news/archive/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m      4\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise an exception for HTTP errors\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Parse the HTML content using BeautifulSoup\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1053\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[0;32m   1056\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1057\u001b[0m         (\n\u001b[0;32m   1058\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1063\u001b[0m         InsecureRequestWarning,\n\u001b[0;32m   1064\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_default_certs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[38;5;241m=\u001b[39mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[38;5;241m=\u001b[39mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    436\u001b[0m     default_ssl_context\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39mversion() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    440\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:402\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ca_certs \u001b[38;5;129;01mor\u001b[39;00m ca_cert_dir \u001b[38;5;129;01mor\u001b[39;00m ca_cert_data:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m         context\u001b[38;5;241m.\u001b[39mload_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIOError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fetch_headlines_for_date(date):\n",
    "    url = f'https://www.wsj.com/news/archive/{date}'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Initialize a list to hold the headlines\n",
    "    headlines = []\n",
    "    \n",
    "    # New York Times articles typically have titles in h2 or h3 tags\n",
    "    for headline in soup.find_all(['h2', 'h3']):\n",
    "        title = headline.get_text(strip=True)\n",
    "        if title:\n",
    "            headlines.append(title)\n",
    "    \n",
    "    # Exclude the last 26 headlines\n",
    "    return headlines[:-26]\n",
    "\n",
    "# Open a CSV file for writing\n",
    "with open('nytimes_headlines_2018_to_2022.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['date', 'headline']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Loop through each date from 2020 to 2023\n",
    "    start_date = datetime(2018, 1, 1)\n",
    "    end_date = datetime(2022,12, 31)\n",
    "    current_date = start_date\n",
    "    \n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime('%Y/%m/%d')\n",
    "        print(f\"Fetching headlines for {date_str}\")\n",
    "        \n",
    "        try:\n",
    "            headlines = fetch_headlines_for_date(date_str)\n",
    "            for headline in headlines:\n",
    "                writer.writerow({'date': date_str, 'headline': headline})\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch headlines for {date_str}: {e}\")\n",
    "        \n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "print(\"Headlines have been saved to nytimes_headlines_2018_to_2022.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6534dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged headlines have been saved to nytimes_headlines_2018_to_2022.csv\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def merge_sentences_by_date(input_csv, output_csv):\n",
    "    # Initialize a dictionary to hold merged sentences by date\n",
    "    date_sentences = defaultdict(list)\n",
    "    \n",
    "    # Read the input CSV file\n",
    "    with open(input_csv, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            date = row['date']\n",
    "            sentence = row['headline']\n",
    "            date_sentences[date].append(sentence)\n",
    "    \n",
    "    # Write the merged results to the output CSV file\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['date', 'headline']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the merged sentences\n",
    "        for date, sentences in date_sentences.items():\n",
    "            merged_sentences = ' '.join(sentences)\n",
    "            writer.writerow({'date': date, 'headline': merged_sentences})\n",
    "\n",
    "# Example usage\n",
    "input_csv = 'nytimes_headlines_2018_to_2022.csv'\n",
    "output_csv = 'nytimes_headlines_2018_to_2022.csv'\n",
    "merge_sentences_by_date(input_csv, output_csv)\n",
    "\n",
    "merge_sentences_by_date(input_csv, output_csv)\n",
    "\n",
    "print(f\"Merged headlines have been saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ae3d23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01</td>\n",
       "      <td>Top News Kim Jong-un Offers North Korea’s Hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/02</td>\n",
       "      <td>Top News The Trump Effect: Business, Anticipat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/03</td>\n",
       "      <td>Top News Hard-Liners and Reformers Tapped Iran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/04</td>\n",
       "      <td>Top News Obstruction Inquiry Shows Trump’s Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/05</td>\n",
       "      <td>Top News Obstruction Inquiry Shows Trump’s Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2022/12/27</td>\n",
       "      <td>Top News George Santos Admits to Lying About C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>2022/12/28</td>\n",
       "      <td>Top News ‘Tragic Battle’: On the Front Lines o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2022/12/29</td>\n",
       "      <td>Top News U.S. Scrambles to Stop Iran From Prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2022/12/30</td>\n",
       "      <td>Top News Russian Missile Barrage Staggers Ukra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2022/12/31</td>\n",
       "      <td>Top News Trump Tax Returns Undermine His Image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                           headline\n",
       "0     2018/01/01  Top News Kim Jong-un Offers North Korea’s Hand...\n",
       "1     2018/01/02  Top News The Trump Effect: Business, Anticipat...\n",
       "2     2018/01/03  Top News Hard-Liners and Reformers Tapped Iran...\n",
       "3     2018/01/04  Top News Obstruction Inquiry Shows Trump’s Str...\n",
       "4     2018/01/05  Top News Obstruction Inquiry Shows Trump’s Str...\n",
       "...          ...                                                ...\n",
       "1819  2022/12/27  Top News George Santos Admits to Lying About C...\n",
       "1820  2022/12/28  Top News ‘Tragic Battle’: On the Front Lines o...\n",
       "1821  2022/12/29  Top News U.S. Scrambles to Stop Iran From Prov...\n",
       "1822  2022/12/30  Top News Russian Missile Barrage Staggers Ukra...\n",
       "1823  2022/12/31  Top News Trump Tax Returns Undermine His Image...\n",
       "\n",
       "[1824 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15ab60f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/01/01</td>\n",
       "      <td>Top News Kim Jong-un Offers North Korea’s Hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/01/02</td>\n",
       "      <td>Top News The Trump Effect: Business, Anticipat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/01/03</td>\n",
       "      <td>Top News Hard-Liners and Reformers Tapped Iran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/01/04</td>\n",
       "      <td>Top News Obstruction Inquiry Shows Trump’s Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/01/05</td>\n",
       "      <td>Top News Obstruction Inquiry Shows Trump’s Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>2022/12/27</td>\n",
       "      <td>Top News George Santos Admits to Lying About C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>2022/12/28</td>\n",
       "      <td>Top News ‘Tragic Battle’: On the Front Lines o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>2022/12/29</td>\n",
       "      <td>Top News U.S. Scrambles to Stop Iran From Prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2022/12/30</td>\n",
       "      <td>Top News Russian Missile Barrage Staggers Ukra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2022/12/31</td>\n",
       "      <td>Top News Trump Tax Returns Undermine His Image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1824 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                           headline\n",
       "0     2018/01/01  Top News Kim Jong-un Offers North Korea’s Hand...\n",
       "1     2018/01/02  Top News The Trump Effect: Business, Anticipat...\n",
       "2     2018/01/03  Top News Hard-Liners and Reformers Tapped Iran...\n",
       "3     2018/01/04  Top News Obstruction Inquiry Shows Trump’s Str...\n",
       "4     2018/01/05  Top News Obstruction Inquiry Shows Trump’s Str...\n",
       "...          ...                                                ...\n",
       "1819  2022/12/27  Top News George Santos Admits to Lying About C...\n",
       "1820  2022/12/28  Top News ‘Tragic Battle’: On the Front Lines o...\n",
       "1821  2022/12/29  Top News U.S. Scrambles to Stop Iran From Prov...\n",
       "1822  2022/12/30  Top News Russian Missile Barrage Staggers Ukra...\n",
       "1823  2022/12/31  Top News Trump Tax Returns Undermine His Image...\n",
       "\n",
       "[1824 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('nytimes_headlines_2018_to_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b966e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weekend_headlines(input_csv, output_csv):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    data = pd.read_csv(input_csv, parse_dates=['date'])\n",
    "\n",
    "    # Ensure the date column is in datetime format\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "    # Sort the DataFrame by date\n",
    "    data = data.sort_values(by='date')\n",
    "\n",
    "    # Initialize a dictionary to collect headlines for each Monday\n",
    "    monday_headlines = {}\n",
    "\n",
    "    # Iterate over the rows to collect weekend headlines and associate them with the following Monday\n",
    "    for index, row in data.iterrows():\n",
    "        date = row['date']\n",
    "        weekday = date.weekday()\n",
    "        if weekday == 5:  # Saturday\n",
    "            next_monday = date + timedelta(days=2)\n",
    "        elif weekday == 6:  # Sunday\n",
    "            next_monday = date + timedelta(days=1)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if next_monday not in monday_headlines:\n",
    "            monday_headlines[next_monday] = {'headline': ''}\n",
    "\n",
    "        monday_headlines[next_monday]['headline'] += ' ' + row['headline']\n",
    "\n",
    "    # Remove Saturday and Sunday rows\n",
    "    weekday_data = data[~data['date'].dt.weekday.isin([5, 6])]\n",
    "\n",
    "    # Append weekend headlines to the following Monday\n",
    "    for next_monday, values in monday_headlines.items():\n",
    "        if next_monday in weekday_data['date'].values:\n",
    "            weekday_data.loc[weekday_data['date'] == next_monday, 'headline'] += values['headline']\n",
    "        else:\n",
    "            new_row = pd.DataFrame({'date': [next_monday], 'headline': [values['headline']]})\n",
    "            weekday_data = pd.concat([weekday_data, new_row], ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame by date again after modification\n",
    "    weekday_data = weekday_data.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "    # Write the updated DataFrame to the output CSV file\n",
    "    weekday_data.to_csv(output_csv, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "530cd9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekend headlines have been adjusted and saved to final_headlines_weekday.csv\n"
     ]
    }
   ],
   "source": [
    "output_csv1 = 'final_headlines_weekday.csv'\n",
    "input_csv1 = 'nytimes_headlines_2018_to_2022.csv'\n",
    "adjust_weekend_headlines(input_csv1, output_csv1)\n",
    "\n",
    "print(f\"Weekend headlines have been adjusted and saved to {output_csv1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b3341de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Top News Kim Jong-un Offers North Korea’s Hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Top News The Trump Effect: Business, Anticipat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Top News Hard-Liners and Reformers Tapped Iran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Top News Obstruction Inquiry Shows Trump’s Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>Top News Obstruction Inquiry Shows Trump’s Str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>Top News George Santos Admits to Lying About C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>Top News ‘Tragic Battle’: On the Front Lines o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>Top News U.S. Scrambles to Stop Iran From Prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>Top News Russian Missile Barrage Staggers Ukra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Top News Trump Tax Returns Undermine His Imag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1305 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                           headline\n",
       "0     2018-01-01  Top News Kim Jong-un Offers North Korea’s Hand...\n",
       "1     2018-01-02  Top News The Trump Effect: Business, Anticipat...\n",
       "2     2018-01-03  Top News Hard-Liners and Reformers Tapped Iran...\n",
       "3     2018-01-04  Top News Obstruction Inquiry Shows Trump’s Str...\n",
       "4     2018-01-05  Top News Obstruction Inquiry Shows Trump’s Str...\n",
       "...          ...                                                ...\n",
       "1300  2022-12-27  Top News George Santos Admits to Lying About C...\n",
       "1301  2022-12-28  Top News ‘Tragic Battle’: On the Front Lines o...\n",
       "1302  2022-12-29  Top News U.S. Scrambles to Stop Iran From Prov...\n",
       "1303  2022-12-30  Top News Russian Missile Barrage Staggers Ukra...\n",
       "1304  2023-01-02   Top News Trump Tax Returns Undermine His Imag...\n",
       "\n",
       "[1305 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(output_csv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46f305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440ae95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0a917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
